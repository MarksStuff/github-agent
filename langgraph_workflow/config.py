"""Configuration for the LangGraph multi-agent workflow."""

import os
from pathlib import Path
from typing import Any

from .constants import (
    CLAUDE_CLI_TIMEOUT,
    DEFAULT_OLLAMA_MODEL,
    OLLAMA_LLAMA3_1,
    OLLAMA_QWEN3_8B,
)

# Workflow configuration
WORKFLOW_CONFIG: dict[str, Any] = {
    # Model routing thresholds
    "escalation_thresholds": {
        "diff_size_lines": 300,  # Lines changed before escalating to Claude
        "files_touched": 10,  # Number of files before escalating
        "consecutive_failures": 2,  # Test failures before escalating
        "complexity_score": 0.7,  # Complexity threshold (0-1)
    },
    # Context and memory limits
    "context_limits": {
        "messages_window": 10,  # Keep last N messages
        "summary_max_tokens": 1000,  # Max tokens for summary
        "artifact_size_limit": 100000,  # Max size for artifact content
        "prompt_max_tokens": 4000,  # Max tokens per prompt
    },
    # Timeouts and retries
    "timeouts": {
        "ci_wait": 1800,  # Max wait for CI (seconds)
        "poll_interval": 30,  # CI polling interval (seconds)
        "model_timeout": 120,  # Model call timeout (seconds)
        "git_operation_timeout": 60,  # Git operation timeout (seconds)
    },
    "retries": {
        "model_calls": 3,  # Retry model calls
        "git_operations": 2,  # Retry git operations
        "ci_checks": 5,  # Retry CI status checks
    },
    # Agent behavior
    "agent_config": {
        "parallel_analysis": True,  # Run initial analyses in parallel
        "random_contribution_order": True,  # Randomize agent order in Phase 2
        "require_unanimous_approval": True,  # All agents must agree on completion
        "allow_arbitration_override": False,  # Can human override agent consensus
    },
    # Quality gates
    "quality_gates": {
        "min_test_coverage": 0.8,  # Minimum test coverage
        "max_lint_errors": 0,  # Maximum lint errors allowed
        "max_complexity": 10,  # Maximum cyclomatic complexity
        "require_ci_pass": True,  # CI must pass before completion
    },
    # Resource limits
    "resource_limits": {
        "max_ollama_concurrent": 4,  # Max concurrent Ollama calls
        "max_claude_concurrent": 1,  # Max concurrent Claude calls
        "max_patch_size": 10000,  # Max lines in a single patch
        "max_artifacts_per_thread": 100,  # Max artifacts per thread
    },
    # GitHub integration
    "github": {
        "labels": {
            "needs_human": "needs-human",
            "conflict": "conflict",
            "arbitrated": "arbitrated",
            "ollama_task": "ollama-task",
            "claude_task": "claude-code-task",
        },
        "pr_template": """## ðŸ¤– Multi-Agent Workflow PR

### Feature
{feature_description}

### Current Phase
{current_phase}

### Agent Consensus
- Test-first: {test_status}
- Fast-coder: {coder_status}
- Senior Engineer: {senior_status}
- Architect: {architect_status}

### Conflicts Requiring Arbitration
{conflicts}

### Human Review Needed
{review_items}

### Artifacts
See: `agents/artifacts/{thread_id}/`

---
*Generated by LangGraph Multi-Agent Workflow*
        """,
    },
    # Paths - stored outside repository in user's home directory
    "paths": {
        "artifacts_root": str(
            Path.home()
            / ".local"
            / "share"
            / "github-agent"
            / "langgraph"
            / "artifacts"
        ),
        "workspaces_root": str(
            Path.home()
            / ".local"
            / "share"
            / "github-agent"
            / "langgraph"
            / "workspaces"
        ),
        "logs_root": str(
            Path.home() / ".local" / "share" / "github-agent" / "langgraph" / "logs"
        ),
        "checkpoints_root": str(
            Path.home()
            / ".local"
            / "share"
            / "github-agent"
            / "langgraph"
            / "checkpoints"
        ),
    },
}

# Model configuration
MODEL_CONFIG: dict[str, Any] = {
    "ollama": {
        "base_url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        "models": {
            "default": OLLAMA_QWEN3_8B,
            "developer": OLLAMA_QWEN3_8B,
            "tester": OLLAMA_LLAMA3_1,
            "summarizer": OLLAMA_LLAMA3_1,
        },
        "parameters": {
            "temperature": 0.7,
            "max_tokens": 4000,
            "top_p": 0.9,
        },
    },
    "claude": {
        "api_key": os.getenv("ANTHROPIC_API_KEY"),
        "models": {
            "default": "claude-3-sonnet-20240229",
            "architect": "claude-3-opus-20240229",
            "reviewer": "claude-3-sonnet-20240229",
        },
        "parameters": {
            "temperature": 0.3,
            "max_tokens": 8000,
        },
    },
    "claude_code": {
        "cli_path": "claude",  # Assuming 'claude' CLI is in PATH
        "timeout": CLAUDE_CLI_TIMEOUT,
        "max_retries": 2,
    },
}

# MCP Server configuration
MCP_CONFIG: dict[str, Any] = {
    "enabled": os.getenv("MCP_ENABLED", "false").lower() == "true",
    "server_url": os.getenv("MCP_SERVER_URL", "http://localhost:8080"),
    "endpoints": {
        "pr_comments": "/api/github/pr/{pr_number}/comments",
        "check_runs": "/api/github/pr/{pr_number}/checks",
        "check_logs": "/api/github/pr/{pr_number}/checks/{check_id}/logs",
    },
}

# Logging configuration
LOGGING_CONFIG: dict[str, Any] = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "standard": {"format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"},
        "detailed": {
            "format": "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"
        },
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "standard",
            "stream": "ext://sys.stdout",
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "DEBUG",
            "formatter": "detailed",
            "filename": "workflow.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5,
        },
    },
    "loggers": {
        "langgraph_workflow": {
            "level": "DEBUG",
            "handlers": ["console", "file"],
            "propagate": False,
        },
        "github_integration": {
            "level": "INFO",
            "handlers": ["console", "file"],
            "propagate": False,
        },
        "agent_personas": {
            "level": "INFO",
            "handlers": ["console", "file"],
            "propagate": False,
        },
    },
    "root": {
        "level": "INFO",
        "handlers": ["console", "file"],
    },
}


def get_config(section: str | None = None) -> dict[str, Any]:
    """Get configuration section or entire config.

    Args:
        section: Config section name (e.g., "workflow", "model", "github")

    Returns:
        Configuration dictionary
    """
    configs = {
        "workflow": WORKFLOW_CONFIG,
        "model": MODEL_CONFIG,
        "mcp": MCP_CONFIG,
        "logging": LOGGING_CONFIG,
    }

    if section:
        return configs.get(section, {})

    return configs


def get_artifacts_path(thread_id: str) -> Path:
    """Get artifacts path for a thread.

    Args:
        thread_id: Thread identifier

    Returns:
        Path to artifacts directory
    """
    root = Path(WORKFLOW_CONFIG["paths"]["artifacts_root"])
    artifacts_path = root / thread_id
    # Ensure directory exists
    artifacts_path.mkdir(parents=True, exist_ok=True)
    return artifacts_path


def get_workspace_path(thread_id: str) -> Path:
    """Get workspace path for a thread.

    Args:
        thread_id: Thread identifier

    Returns:
        Path to workspace directory
    """
    root = Path(WORKFLOW_CONFIG["paths"]["workspaces_root"])
    workspace_path = root / thread_id
    # Ensure directory exists
    workspace_path.mkdir(parents=True, exist_ok=True)
    return workspace_path


def get_checkpoint_path(name: str = "agent_state") -> str:
    """Get path for a checkpoint database file.

    Args:
        name: Base name for the checkpoint file (without .db extension)

    Returns:
        Full path to the checkpoint database file
    """
    root = Path(WORKFLOW_CONFIG["paths"]["checkpoints_root"])
    # Ensure directory exists
    root.mkdir(parents=True, exist_ok=True)
    return str(root / f"{name}.db")


def should_escalate_to_claude(
    diff_size: int | None = None,
    files_touched: int | None = None,
    consecutive_failures: int | None = None,
    complexity_score: float | None = None,
) -> bool:
    """Determine if task should escalate to Claude.

    Args:
        diff_size: Number of lines changed
        files_touched: Number of files modified
        consecutive_failures: Number of consecutive test failures
        complexity_score: Task complexity score (0-1)

    Returns:
        True if should escalate to Claude
    """
    thresholds = WORKFLOW_CONFIG["escalation_thresholds"]

    if diff_size and diff_size >= thresholds["diff_size_lines"]:
        return True

    if files_touched and files_touched >= thresholds["files_touched"]:
        return True

    if (
        consecutive_failures
        and consecutive_failures >= thresholds["consecutive_failures"]
    ):
        return True

    if complexity_score and complexity_score > thresholds["complexity_score"]:
        return True

    return False


# Model configuration utility functions
def get_ollama_base_url() -> str:
    """Get Ollama base URL from configuration.

    Returns:
        Ollama base URL (sourced from environment or config)
    """
    return MODEL_CONFIG["ollama"]["base_url"]


def get_ollama_model(agent_type: str = "default") -> str:
    """Get Ollama model name for agent type.

    Args:
        agent_type: Type of agent ("default", "developer", "tester", "summarizer")

    Returns:
        Model name from configuration
    """
    return MODEL_CONFIG["ollama"]["models"].get(agent_type, DEFAULT_OLLAMA_MODEL)


def get_claude_cli_timeout() -> int:
    """Get Claude CLI timeout from configuration.

    Returns:
        Timeout in seconds
    """
    return MODEL_CONFIG["claude_code"]["timeout"]


def get_claude_cli_path() -> str:
    """Get Claude CLI executable path.

    Returns:
        Path to Claude CLI executable
    """
    return MODEL_CONFIG["claude_code"]["cli_path"]
